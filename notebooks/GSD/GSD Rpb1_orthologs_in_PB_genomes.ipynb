{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSD: Rpb1 orthologs in PB genomes\n",
    "\n",
    "This collects Rpb1 gene and protein sequences from a collection of PacBio sequenced yeast genomes from [Yue et al 2017](https://www.ncbi.nlm.nih.gov/pubmed/28416820). It builds on the notebook [Searching for coding sequences in genomes using BLAST and Python](notebooks/Searching%20for%20coding%20sequences%20in%20genomes%20using%20BLAST%20and%20Python.ipynb).\n",
    "\n",
    "Reference for sequence data:  \n",
    "[Contrasting evolutionary genome dynamics between domesticated and wild yeasts.\n",
    "Yue JX, Li J, Aigrain L, Hallin J, Persson K, Oliver K, BergstrÃ¶m A, Coupland P, Warringer J, Lagomarsino MC, Fischer G, Durbin R, Liti G. Nat Genet. 2017 Jun;49(6):913-924. doi: 10.1038/ng.3847. Epub 2017 Apr 17. PMID: 28416820](https://www.ncbi.nlm.nih.gov/pubmed/28416820)\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Get scripts and sequence data necessary.\n",
    "\n",
    "(Caveat: right now this is written for genes with no introns. Only a few hundred have in yeast and that is the organism in this example. Intron presence would only become important when trying to translate in late stages of this workflow.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name = \"RPB1\"\n",
    "size_expected = 5202\n",
    "get_seq_from_link = False\n",
    "link_to_FASTA_of_gene = \"https://gist.githubusercontent.com/fomightez/f46b0624f1d8e3abb6ff908fc447e63b/raw/625eaba76bb54e16032f90c8812350441b753a0c/uz_S288C_YOR270C_VPH1_coding.fsa\"\n",
    "#**Possible future enhancement would be to add getting the FASTA of the gene from Yeastmine with just systematic id**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the genomes data, the `blast_to_df` script, and sequence to search for matches in the genomes by running these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13759  100 13759    0     0  98278      0 --:--:-- --:--:-- --:--:-- 98278\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3560      0 --:--:-- --:--:-- --:--:--  3560\n",
      "100 3687k  100 3687k    0     0  17.2M      0 --:--:-- --:--:-- --:--:-- 17.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   6846      0 --:--:-- --:--:-- --:--:--  6846\n",
      "100 3387k  100 3387k    0     0  17.2M      0 --:--:-- --:--:-- --:--:-- 17.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   5235      0 --:--:-- --:--:-- --:--:--  5235\n",
      "100 3348k  100 3348k    0     0  17.8M      0 --:--:-- --:--:-- --:--:-- 17.8M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   5235      0 --:--:-- --:--:-- --:--:--  5393\n",
      "100 3406k  100 3406k    0     0  17.5M      0 --:--:-- --:--:-- --:--:-- 17.5M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   5235      0 --:--:-- --:--:-- --:--:--  5235\n",
      "100 3357k  100 3357k    0     0  18.2M      0 --:--:-- --:--:-- --:--:-- 18.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   5393      0 --:--:-- --:--:-- --:--:--  5393\n",
      "100 3375k  100 3375k    0     0  18.6M      0 --:--:-- --:--:-- --:--:-- 18.6M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3490      0 --:--:-- --:--:-- --:--:--  3490\n",
      "100 3332k  100 3332k    0     0  13.6M      0 --:--:-- --:--:-- --:--:-- 13.6M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   5393      0 --:--:-- --:--:-- --:--:--  5235\n",
      "100 3658k  100 3658k    0     0  16.6M      0 --:--:-- --:--:-- --:--:-- 16.6M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2170      0 --:--:-- --:--:-- --:--:--  2170\n",
      "100 3350k  100 3350k    0     0  13.8M      0 --:--:-- --:--:-- --:--:-- 13.8M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   5235      0 --:--:-- --:--:-- --:--:--  5235\n",
      "100 3349k  100 3349k    0     0  18.0M      0 --:--:-- --:--:-- --:--:-- 18.0M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   5393      0 --:--:-- --:--:-- --:--:--  5393\n",
      "100 3701k  100 3701k    0     0  20.4M      0 --:--:-- --:--:-- --:--:-- 20.4M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   5235      0 --:--:-- --:--:-- --:--:--  5235\n",
      "100 3362k  100 3362k    0     0  18.5M      0 --:--:-- --:--:-- --:--:-- 18.5M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_needed = \"blast_to_df.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/blast-utilities/blast_to_df.py\n",
    "import pandas as pd\n",
    "# Prepare for getting PacBio (Yue et al 2017 sequences)\n",
    "#make a list of the strain designations\n",
    "yue_et_al_strains = [\"S288C\",\"DBVPG6044\",\"DBVPG6765\",\"SK1\",\"Y12\",\n",
    "                     \"YPS128\",\"UWOPS034614\",\"CBS432\",\"N44\",\"YPS138\",\n",
    "                     \"UFRJ50816\",\"UWOPS919171\"]\n",
    "# Get & unpack the genome sequences from strains \n",
    "for s in yue_et_al_strains:\n",
    "    !curl -LO http://yjx1217.github.io/Yeast_PacBio_2016/data/Nuclear_Genome/{s}.genome.fa.gz\n",
    "    !gunzip -f {s}.genome.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "S288C.genome.fa chromosome identifiers tagged.\n",
      "DBVPG6044.genome.fa chromosome identifiers tagged.\n",
      "DBVPG6765.genome.fa chromosome identifiers tagged.\n",
      "SK1.genome.fa chromosome identifiers tagged.\n",
      "Y12.genome.fa chromosome identifiers tagged.\n",
      "YPS128.genome.fa chromosome identifiers tagged.\n",
      "UWOPS034614.genome.fa chromosome identifiers tagged.\n",
      "CBS432.genome.fa chromosome identifiers tagged.\n",
      "N44.genome.fa chromosome identifiers tagged.\n",
      "YPS138.genome.fa chromosome identifiers tagged.\n",
      "UFRJ50816.genome.fa chromosome identifiers tagged.\n",
      "UWOPS919171.genome.fa chromosome identifiers tagged."
     ]
    }
   ],
   "source": [
    "# add identifiers to each `chr` so results for each strain clear later\n",
    "chromosome_id_prefix = \"chr\"\n",
    "def add_strain_id_to_description_line(file,strain_id):\n",
    "    '''\n",
    "    Takes a file and edits every description line to add \n",
    "    strain_id after the caret.\n",
    "    \n",
    "    Saves the fixed file\n",
    "    '''\n",
    "    import sys\n",
    "    output_file_name = \"temp.txt\"\n",
    "    # prepare output file for saving so it will be open and ready\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "\n",
    "        # read in the input file\n",
    "        with open(file, 'r') as input_handler:\n",
    "            # prepare to give feeback later or allow skipping to certain start\n",
    "            lines_processed = 0\n",
    "\n",
    "            for line in input_handler:\n",
    "                lines_processed += 1\n",
    "                if line.startswith(\">\"):\n",
    "                    rest_o_line = line.split(\">\")\n",
    "                    new_line = \">\"+strain_id + rest_o_line[1]\n",
    "                else:\n",
    "                    new_line = line\n",
    "                \n",
    "                # Send text to output\n",
    "                output_file.write(new_line)\n",
    "\n",
    "    \n",
    "    # replace the original file with edited\n",
    "    !mv temp.txt {file}\n",
    "    # Feedback\n",
    "    sys.stderr.write(\"\\n{} chromosome identifiers tagged.\".format(file))\n",
    "\n",
    "for s in yue_et_al_strains:\n",
    "    add_strain_id_to_description_line(s+\".genome.fa\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EDIT THE FILE 'RPB1.fsa' TO CONTAIN YOUR GENE OF INTEREST (FASTA-FORMATTED)."
     ]
    }
   ],
   "source": [
    "# Get SGD gene sequence in FASTA format to search for best matches in the genomes\n",
    "import sys\n",
    "gene_filen = gene_name + \".fsa\"\n",
    "if get_seq_from_link:\n",
    "    !curl -o {gene_filen} {link_to_FASTA_of_gene}\n",
    "else:\n",
    "    !touch {gene_filen}\n",
    "    sys.stderr.write(\"\\nEDIT THE FILE '{}' TO CONTAIN \"\n",
    "        \"YOUR GENE OF INTEREST (FASTA-FORMATTED)\"\n",
    "        \".\".format(gene_filen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I PUT CONTENTS OF FILE `S288C_YDL140C_RPO21_coding.fsa` downloaded from [here](https://www.yeastgenome.org/locus/S000002299/sequence) as 'RPB1.fsa'.**\n",
    "\n",
    "Now you are prepared to run BLAST to search each PacBio-sequenced genomes for the best match to a gene from the Saccharomyces cerevisiae strain S288C reference sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BLAST to search the genomes for matches to the gene in the reference genome at SGD\n",
    "\n",
    "SGD is the [Saccharomyces cerevisiae Genome Database site](http:yeastgenome.org) and the reference genome is from S288C.\n",
    "\n",
    "This is going to go through each genome and make a database so it is searchable and then search for matches to the gene. The information on the best match will be collected. One use for that information will be collecting the corresponding sequences later.\n",
    "\n",
    "Import the script that allows sending BLAST output to Python dataframes so that we can use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blast_to_df import blast_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DBVPG6044.genome.fa',\n",
       " 'DBVPG6765.genome.fa',\n",
       " 'CBS432.genome.fa',\n",
       " 'YPS128.genome.fa',\n",
       " 'UFRJ50816.genome.fa',\n",
       " 'S288C.genome.fa',\n",
       " 'SK1.genome.fa',\n",
       " 'UWOPS034614.genome.fa',\n",
       " 'UWOPS919171.genome.fa',\n",
       " 'YPS138.genome.fa',\n",
       " 'N44.genome.fa',\n",
       " 'Y12.genome.fa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of all `genome.fa` files, excluding `genome.fa.nhr` and `genome.fa.nin` and `genome.fansq`\n",
    "# The excluding was only necessary because I had run some queries preliminarily in development. Normally, it would just be the `.re.fa` at the outset.\n",
    "fn_to_check = \"genome.fa\" \n",
    "genomes = []\n",
    "import os\n",
    "import fnmatch\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, '*'+fn_to_check):\n",
    "        if not file.endswith(\".nhr\") and not file.endswith(\".nin\") and not file.endswith(\".nsq\") :\n",
    "            genomes.append(file)\n",
    "genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:40\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/DBVPG6044.genome.fa\n",
      "New DB title:  DBVPG6044.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.109964 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:41\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/DBVPG6765.genome.fa\n",
      "New DB title:  DBVPG6765.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.107654 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:42\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/CBS432.genome.fa\n",
      "New DB title:  CBS432.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.120981 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:43\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/YPS128.genome.fa\n",
      "New DB title:  YPS128.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.127451 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:44\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/UFRJ50816.genome.fa\n",
      "New DB title:  UFRJ50816.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.145046 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:44\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/S288C.genome.fa\n",
      "New DB title:  S288C.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.149116 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:45\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/SK1.genome.fa\n",
      "New DB title:  SK1.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.119755 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:46\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/UWOPS034614.genome.fa\n",
      "New DB title:  UWOPS034614.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.13628 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:47\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/UWOPS919171.genome.fa\n",
      "New DB title:  UWOPS919171.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.122875 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:48\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/YPS138.genome.fa\n",
      "New DB title:  YPS138.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.115273 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:49\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/N44.genome.fa\n",
      "New DB title:  N44.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.126019 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 03:28:50\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Untitled Folder/Y12.genome.fa\n",
      "New DB title:  Y12.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.129014 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    }
   ],
   "source": [
    "SGD_gene = gene_filen\n",
    "dfs = []\n",
    "for genome in genomes:\n",
    "    !makeblastdb -in {genome} -dbtype nucl\n",
    "    result = !blastn -query {SGD_gene} -db {genome} -outfmt \"6 qseqid sseqid stitle pident qcovs length mismatch gapopen qstart qend sstart send qframe sframe frames evalue bitscore qseq sseq\"\n",
    "    from blast_to_df import blast_to_df\n",
    "    blast_df = blast_to_df(result.n)\n",
    "    dfs.append(blast_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes in the list `dfs` into one dataframe\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the df\n",
    "filen_prefix = gene_name + \"_orthologBLASTdf\"\n",
    "df.to_pickle(filen_prefix+\".pkl\")\n",
    "df.to_csv(filen_prefix+'.tsv', sep='\\t',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qseqid</th>\n",
       "      <th>sseqid</th>\n",
       "      <th>stitle</th>\n",
       "      <th>pident</th>\n",
       "      <th>qcovs</th>\n",
       "      <th>length</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gapopen</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>sstart</th>\n",
       "      <th>send</th>\n",
       "      <th>qframe</th>\n",
       "      <th>sframe</th>\n",
       "      <th>frames</th>\n",
       "      <th>evalue</th>\n",
       "      <th>bitscore</th>\n",
       "      <th>qseq</th>\n",
       "      <th>sseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>DBVPG6044chrIV</td>\n",
       "      <td>DBVPG6044chrIV</td>\n",
       "      <td>99.020</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>216501</td>\n",
       "      <td>211321</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>DBVPG6765chrIV</td>\n",
       "      <td>DBVPG6765chrIV</td>\n",
       "      <td>99.885</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>211477</td>\n",
       "      <td>206276</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9574</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>CBS432chrIV</td>\n",
       "      <td>CBS432chrIV</td>\n",
       "      <td>92.522</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>211739</td>\n",
       "      <td>206559</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7432</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGTCAACAGTATTCGAGTGCTCCACTCCGTACAGTGAAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>YPS128chrIV</td>\n",
       "      <td>YPS128chrIV</td>\n",
       "      <td>99.923</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>210086</td>\n",
       "      <td>204885</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9585</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>92.368</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>213091</td>\n",
       "      <td>207932</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7369</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>S288CchrIV</td>\n",
       "      <td>S288CchrIV</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>210502</td>\n",
       "      <td>205301</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9607</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>SK1chrIV</td>\n",
       "      <td>SK1chrIV</td>\n",
       "      <td>99.020</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>222692</td>\n",
       "      <td>217512</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>UWOPS034614chrIV</td>\n",
       "      <td>UWOPS034614chrIV</td>\n",
       "      <td>99.500</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>209007</td>\n",
       "      <td>203827</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9443</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>UWOPS919171chrIV</td>\n",
       "      <td>UWOPS919171chrIV</td>\n",
       "      <td>92.272</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>219693</td>\n",
       "      <td>214492</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7380</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>YPS138chrIV</td>\n",
       "      <td>YPS138chrIV</td>\n",
       "      <td>92.695</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>211802</td>\n",
       "      <td>206622</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7481</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>N44chrIV</td>\n",
       "      <td>N44chrIV</td>\n",
       "      <td>93.195</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>212185</td>\n",
       "      <td>207005</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7625</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGTCAACAGTATTCGAGTGCTCCACTCCGTACAGTGAAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>Y12chrIV</td>\n",
       "      <td>Y12chrIV</td>\n",
       "      <td>99.923</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>211561</td>\n",
       "      <td>206360</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9585</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qseqid            sseqid            stitle   pident  qcovs  length  \\\n",
       "0  RPO21    DBVPG6044chrIV    DBVPG6044chrIV   99.020    100    5202   \n",
       "0  RPO21    DBVPG6765chrIV    DBVPG6765chrIV   99.885    100    5202   \n",
       "0  RPO21       CBS432chrIV       CBS432chrIV   92.522    100    5202   \n",
       "0  RPO21       YPS128chrIV       YPS128chrIV   99.923    100    5202   \n",
       "0  RPO21    UFRJ50816chrXI    UFRJ50816chrXI   92.368    100    5202   \n",
       "0  RPO21        S288CchrIV        S288CchrIV  100.000    100    5202   \n",
       "0  RPO21          SK1chrIV          SK1chrIV   99.020    100    5202   \n",
       "0  RPO21  UWOPS034614chrIV  UWOPS034614chrIV   99.500    100    5202   \n",
       "0  RPO21  UWOPS919171chrIV  UWOPS919171chrIV   92.272    100    5202   \n",
       "0  RPO21       YPS138chrIV       YPS138chrIV   92.695    100    5202   \n",
       "0  RPO21          N44chrIV          N44chrIV   93.195    100    5202   \n",
       "0  RPO21          Y12chrIV          Y12chrIV   99.923    100    5202   \n",
       "\n",
       "   mismatch  gapopen  qstart  qend  sstart    send  qframe  sframe frames  \\\n",
       "0        30       11       1  5202  216501  211321       1      -1   1/-1   \n",
       "0         6        0       1  5202  211477  206276       1      -1   1/-1   \n",
       "0       368        1       1  5202  211739  206559       1      -1   1/-1   \n",
       "0         4        0       1  5202  210086  204885       1      -1   1/-1   \n",
       "0       355        9       1  5202  213091  207932       1      -1   1/-1   \n",
       "0         0        0       1  5202  210502  205301       1      -1   1/-1   \n",
       "0        30       11       1  5202  222692  217512       1      -1   1/-1   \n",
       "0         5        1       1  5202  209007  203827       1      -1   1/-1   \n",
       "0       402        0       1  5202  219693  214492       1      -1   1/-1   \n",
       "0       359        1       1  5202  211802  206622       1      -1   1/-1   \n",
       "0       333        1       1  5202  212185  207005       1      -1   1/-1   \n",
       "0         4        0       1  5202  211561  206360       1      -1   1/-1   \n",
       "\n",
       "   evalue  bitscore                                               qseq  \\\n",
       "0     0.0      9304  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9574  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7432  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9585  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7369  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9607  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9304  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9443  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7380  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7481  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7625  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9585  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "\n",
       "                                                sseq  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGTCAACAGTATTCGAGTGCTCCACTCCGTACAGTGAAGG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...  \n",
       "0  ATGGTAGGTCAACAGTATTCGAGTGCTCCACTCCGTACAGTGAAGG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computationally check if any genomes missing from the BLAST results list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: 12\n",
      "results: 12\n",
      "missing: 0\n"
     ]
    }
   ],
   "source": [
    "subjids = df.sseqid.tolist()\n",
    "#print (subjids)\n",
    "#print (subjids[0:10])\n",
    "subjids = [x.split(chromosome_id_prefix)[0] for x in subjids]\n",
    "#print (subjids)\n",
    "#print (subjids[0:10])\n",
    "len_genome_fn_end = len(fn_to_check) + 1 # plus one to accound for the period that will be \n",
    "# between `fn_to_check` and strain_id`, such as `SK1.genome.fa`\n",
    "genome_ids = [x[:-len_genome_fn_end] for x in genomes]\n",
    "#print (genome_ids[0:10])\n",
    "\n",
    "a = set(genome_ids)\n",
    "#print (a)\n",
    "print (\"initial:\",len(a))\n",
    "r = set(subjids)\n",
    "print(\"results:\",len(r))\n",
    "print (\"missing:\",len(a-r))\n",
    "#a - r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: Report on how expected size compares to max size seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected size of gene: 5202\n",
      "Most frequent size of matches: 5202\n",
      "Maximum size of matches: 5202\n"
     ]
    }
   ],
   "source": [
    "size_seen = df.length.max(0)\n",
    "print (\"Expected size of gene:\", size_expected)\n",
    "print (\"Most frequent size of matches:\", df.length.mode()[0])\n",
    "print (\"Maximum size of matches:\", df.length.max(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the identified, raw sequences\n",
    "\n",
    "Get the expected size centered on the best match, plus a little flanking each because they might not exactly cover the entire open reading frame. (Although, the example here all look to be full size.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16612  100 16612    0     0  96581      0 --:--:-- --:--:-- --:--:-- 96581\n",
      "Requirement already satisfied: pyfaidx in /srv/conda/lib/python3.6/site-packages (0.5.5.2)\n",
      "Requirement already satisfied: six in /srv/conda/lib/python3.6/site-packages (from pyfaidx) (1.12.0)\n",
      "Requirement already satisfied: setuptools>=0.7 in /srv/conda/lib/python3.6/site-packages (from pyfaidx) (40.6.3)\n"
     ]
    }
   ],
   "source": [
    "# Get the script for extracting based on position (and install dependency pyfaidx)\n",
    "import os\n",
    "file_needed = \"extract_regions_from_clustal_alignment.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/Extract_from_FASTA/extract_subsequence_from_FASTA.py\n",
    "!pip install pyfaidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6044chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6765chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedCBS432chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS128chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUFRJ50816chrXI.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedS288CchrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedSK1chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS034614chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS919171chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS138chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedN44chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedY12chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Collected RAW sequences gathered and saved as `RPB1_raw_ortholog_seqs.tar.gz`."
     ]
    }
   ],
   "source": [
    "size_expected = size_expected # use value from above, or alter at this point.\n",
    "#size_expected = df.length.max(0) #bp length of SGD coding sequence; should be equivalent and that way not hardcoded?\n",
    "extra_add_to_start = 51 #to allow for 'fuzziness' at starting end\n",
    "extra_add_to_end = 51 #to allow for 'fuzziness' at far end\n",
    "genome_fn_end = \"genome.fa\" \n",
    "\n",
    "\n",
    "def midpoint(items):\n",
    "    '''\n",
    "    takes a iterable of items and returns the midpoint (integer) of the first \n",
    "    and second values\n",
    "    '''\n",
    "    return int((int(items[0])+int(items[1]))/2)\n",
    "\n",
    "#midpoint((1,100))\n",
    "\n",
    "def determine_pos_to_get(match_start,match_end):\n",
    "    '''\n",
    "    Take the start and end of the matched region.\n",
    "    \n",
    "    Calculate midpoint between those and then \n",
    "    center expected size on that to determine\n",
    "    preliminary start and preliminary end to get.\n",
    "    Add the extra basepairs to get at each end\n",
    "    to allow for fuzziness/differences of actual\n",
    "    gene ends for orthologs. \n",
    "    Return the final start and end positions to get.\n",
    "    \n",
    "    '''\n",
    "    center_of_match = midpoint((match_start,match_end))\n",
    "    half_size_expected = int(size_expected/2.0)\n",
    "    if size_expected % 2 != 0:\n",
    "        half_size_expected += 1\n",
    "    start_pos = center_of_match - half_size_expected\n",
    "    end_pos = center_of_match + half_size_expected\n",
    "    start_pos -= extra_add_to_start\n",
    "    end_pos += extra_add_to_end \n",
    "    return start_pos, end_pos\n",
    "\n",
    "\n",
    "# go through the dataframe using information on each to come up with sequence file, \n",
    "# specific indentifier within sequence file, and the start and end to extract\n",
    "# store these valaues as a list in a dictionary with the strain identifier as the key.\n",
    "extracted_info = {}\n",
    "start,end = 0,0\n",
    "for row in df.itertuples():\n",
    "    #print (row.length)\n",
    "    start_to_get, end_to_get = determine_pos_to_get(row.sstart, row.send)\n",
    "    posns_to_get = \"{}-{}\".format(start_to_get, end_to_get)\n",
    "    record_id = row.sseqid\n",
    "    strain_id = row.sseqid.split(chromosome_id_prefix)[0]\n",
    "    seq_fn = strain_id + \".\" + genome_fn_end\n",
    "    extracted_info[strain_id] = [seq_fn, record_id, posns_to_get]\n",
    "# Use the dictionary to get the sequences\n",
    "for id_ in extracted_info:\n",
    "    #%run extract_subsequence_from_FASTA.py {*extracted_info[id_]} #unpacking doesn't seem to work here in `%run`\n",
    "    %run extract_subsequence_from_FASTA.py {extracted_info[id_][0]} {extracted_info[id_][1]} {extracted_info[id_][2]}\n",
    "\n",
    "#package up the retrieved sequences\n",
    "archive_file_name = gene_name+\"_raw_ortholog_seqs.tar.gz\"\n",
    "# make list of extracted files using fnmatch\n",
    "fn_part_to_match = \"seq_extracted\"\n",
    "collected_seq_files_list = []\n",
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, fn_part_to_match+'*'):\n",
    "        #print (file)\n",
    "        collected_seq_files_list.append(file)\n",
    "!tar czf {archive_file_name} {\" \".join(collected_seq_files_list)} # use the list for archiving command\n",
    "sys.stderr.write(\"\\n\\nCollected RAW sequences gathered and saved as \"\n",
    "                 \"`{}`.\".format(archive_file_name))\n",
    "# move the collected raw sequences to a folder in preparation for\n",
    "# extracting encoding sequence from original source below\n",
    "!mkdir raw\n",
    "!mv seq_extracted*.fa raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That archive should contain the \"raw\" sequence for each gene, even if the ends are a little different for each. At minimum the entire gene sequence needs to be there at this point; extra at each end is preferable at this point.\n",
    "\n",
    "You should inspect them as soon as possible and adjust the extra sequence to add higher or lower depending on whether the ortholog genes vary more or less, respectively. The reason they don't need to be perfect yet though is because next we are going to extract the longest open reading frame, which presumably demarcates the entire gene. Then we can return to use that information to clean up the collected sequences to just be the coding sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect protein translations of the genes and then clean up \"raw\" sequences to just be coding\n",
    "\n",
    "We'll assume the longest translatable frame in the collected \"raw\" sequences encodes the protein sequence for the gene orthologs of interest. Well base these steps on the [section '20.1.13  Identifying open reading frames'](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc299) in the present version of the [Biopython Tutorial and Cookbook](http://biopython.org/DIST/docs/tutorial/Tutorial.html) (Last Update â 18 December 2018 (Biopython 1.73)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(First run the next cell to get a script needed for dealing with the strand during the translation and gathering of thge encoding sequence.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8851  100  8851    0     0  64137      0 --:--:-- --:--:-- --:--:-- 64137\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_needed = \"convert_fasta_to_reverse_complement.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/ConvertSeq/convert_fasta_to_reverse_complement.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to perform the work described in the header to this section..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/Bio/Seq.py:2576: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  BiopythonWarning)\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6044chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `DBVPG6044_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'DBVPG6044_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'DBVPG6044_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In DBVPG6044_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `DBVPG6044_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedS288CchrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `S288C_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'S288C_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'S288C_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In S288C_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `S288C_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS138chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `YPS138_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'YPS138_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'YPS138_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In YPS138_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `YPS138_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS034614chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UWOPS034614_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UWOPS034614_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UWOPS034614_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UWOPS034614_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UWOPS034614_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6765chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `DBVPG6765_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'DBVPG6765_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'DBVPG6765_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In DBVPG6765_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `DBVPG6765_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS128chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `YPS128_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'YPS128_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'YPS128_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In YPS128_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `YPS128_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedSK1chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `SK1_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'SK1_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'SK1_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In SK1_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `SK1_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedCBS432chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `CBS432_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'CBS432_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'CBS432_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In CBS432_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `CBS432_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS919171chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UWOPS919171_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UWOPS919171_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UWOPS919171_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UWOPS919171_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UWOPS919171_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUFRJ50816chrXI.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UFRJ50816_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UFRJ50816_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UFRJ50816_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UFRJ50816_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UFRJ50816_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedY12chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `Y12_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'Y12_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'Y12_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In Y12_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `Y12_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedN44chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `N44_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'N44_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'N44_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In N44_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `N44_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********"
     ]
    }
   ],
   "source": [
    "# find the featured open reading frame and collect presumed protein sequences\n",
    "# Collect the corresponding encoding sequence from the original source\n",
    "def len_ORF(items):\n",
    "    # orf is fourth item in the tuples\n",
    "    return len(items[3])\n",
    "def find_orfs_with_trans(seq, trans_table, min_protein_length):\n",
    "    '''\n",
    "    adapted from the present section '20.1.13  Identifying open reading frames'\n",
    "    http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc299 in the \n",
    "    present version of the [Biopython Tutorial and Cookbook at \n",
    "    http://biopython.org/DIST/docs/tutorial/Tutorial.html \n",
    "    (Last Update â 18 December 2018 (Biopython 1.73)\n",
    "    Same as there except altered to sort on the length of the\n",
    "    open reading frame.\n",
    "    '''\n",
    "    answer = []\n",
    "    seq_len = len(seq)\n",
    "    for strand, nuc in [(+1, seq), (-1, seq.reverse_complement())]:\n",
    "        for frame in range(3):\n",
    "            trans = str(nuc[frame:].translate(trans_table))\n",
    "            trans_len = len(trans)\n",
    "            aa_start = 0\n",
    "            aa_end = 0\n",
    "            while aa_start < trans_len:\n",
    "                aa_end = trans.find(\"*\", aa_start)\n",
    "                if aa_end == -1:\n",
    "                    aa_end = trans_len\n",
    "                if aa_end-aa_start >= min_protein_length:\n",
    "                    if strand == 1:\n",
    "                        start = frame+aa_start*3\n",
    "                        end = min(seq_len,frame+aa_end*3+3)\n",
    "                    else:\n",
    "                        start = seq_len-frame-aa_end*3-3\n",
    "                        end = seq_len-frame-aa_start*3\n",
    "                    answer.append((start, end, strand,\n",
    "                                   trans[aa_start:aa_end]))\n",
    "                aa_start = aa_end+1\n",
    "    answer.sort(key=len_ORF, reverse = True)\n",
    "    return answer\n",
    "\n",
    "def generate_rcoutput_file_name(file_name,suffix_for_saving = \"_rc\"):\n",
    "    '''\n",
    "    from https://github.com/fomightez/sequencework/blob/master/ConvertSeq/convert_fasta_to_reverse_complement.py\n",
    "    Takes a file name as an argument and returns string for the name of the\n",
    "    output file. The generated name is based on the original file\n",
    "    name.\n",
    "    Specific example\n",
    "    =================\n",
    "    Calling function with\n",
    "        (\"sequence.fa\", \"_rc\")\n",
    "    returns\n",
    "        \"sequence_rc.fa\"\n",
    "    '''\n",
    "    main_part_of_name, file_extension = os.path.splitext(\n",
    "        file_name) #from \n",
    "    #http://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python\n",
    "    if '.' in file_name:  #I don't know if this is needed with the os.path.splitext method but I had it before so left it\n",
    "        return main_part_of_name + suffix_for_saving  + file_extension\n",
    "    else:\n",
    "        return file_name + suffix_for_saving + \".fa\"\n",
    "    \n",
    "def add_strand_to_description_line(file,strand=\"-1\"):\n",
    "    '''\n",
    "    Takes a file and edits description line to add \n",
    "    strand info at end.\n",
    "    \n",
    "    Saves the fixed file\n",
    "    '''\n",
    "    import sys\n",
    "    output_file_name = \"temp.txt\"\n",
    "    # prepare output file for saving so it will be open and ready\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "\n",
    "        # read in the input file\n",
    "        with open(file, 'r') as input_handler:\n",
    "            # prepare to give feeback later or allow skipping to certain start\n",
    "            lines_processed = 0\n",
    "\n",
    "            for line in input_handler:\n",
    "                lines_processed += 1\n",
    "                if line.startswith(\">\"):\n",
    "                    new_line = line.strip() + \"; {} strand\\n\".format(strand)\n",
    "                else:\n",
    "                    new_line = line\n",
    "                \n",
    "                # Send text to output\n",
    "                output_file.write(new_line)\n",
    "\n",
    "    \n",
    "    # replace the original file with edited\n",
    "    !mv temp.txt {file}\n",
    "    # Feedback\n",
    "    sys.stderr.write(\"\\nIn {}, strand noted.\".format(file))\n",
    "\n",
    "table = 1 #sets translation table to standard nuclear, see \n",
    "# https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi\n",
    "min_pro_len = 80 #cookbook had the standard `100`. Feel free to adjust.\n",
    "prot_seqs_info = {} #collect as dictionary with strain_id as key. Values to\n",
    "# be list with source id as first item and protein length as second and \n",
    "# strand in source seq as third item, and start and end in source sequence as fourth and fifth,\n",
    "# and file name of protein and gene as sixth and seventh.\n",
    "# Example key and value pair: 'YPS138':['<source id>','<protein length>',-1,52,2626,'<gene file name>','<protein file name>']\n",
    "gene_seqs_fn_list = []\n",
    "prot_seqs_fn_list = []\n",
    "from Bio import SeqIO\n",
    "for raw_seq_filen in collected_seq_files_list:\n",
    "    #strain_id = raw_seq_filen[:-len_genome_fn_end] #if was dealing with source seq\n",
    "    strain_id = raw_seq_filen.split(chromosome_id_prefix)[0].split(\"seq_extracted\")[1]\n",
    "    record = SeqIO.read(\"raw/\"+raw_seq_filen,\"fasta\")\n",
    "    raw_seq_source_fn = strain_id + \".\" + genome_fn_end\n",
    "    raw_seq_source_id = record.description.split(\":\")[0]\n",
    "    orf_list = find_orfs_with_trans(record.seq, table, min_pro_len)\n",
    "    orf_start, orf_end, strand, prot_seq = orf_list[0] #longest ORF seq for protein coding\n",
    "    \n",
    "    location_raw_seq = record.description.rsplit(\":\",1)[1] #get to use in calculating\n",
    "    # the start and end position in original genome sequence.\n",
    "    raw_loc_parts = location_raw_seq.split(\"-\")\n",
    "    start_from_raw_seq = int(raw_loc_parts[0])\n",
    "    end_from_raw_seq = int(raw_loc_parts[1])\n",
    "    length_extracted = len(record) #also to use in calculating relative original\n",
    "    \n",
    "    # Trim back to the first Methionine, assumed to be the initiating MET.\n",
    "    # (THIS MIGHT BE A SOURCE OF EXTRA 'LEADING' RESIDUES IN SOME CASES & ARGUES \n",
    "    # FOR LIMITING THE AMOUNT OF FLANKING SEQUENCE ADDED TO ALLOW FOR FUZINESS.)\n",
    "    try:\n",
    "        amt_resi_to_trim = prot_seq.index(\"M\")\n",
    "    except ValueError:\n",
    "        sys.stderr.write(\"**ERROR**When searching for initiating methionine,\\n\"\n",
    "                         \"no Methionine found in the traslated protein sequence.**ERROR**\")\n",
    "        sys.exit(1)\n",
    "    prot_seq = prot_seq[amt_resi_to_trim:]\n",
    "    len_seq_trimmed = amt_resi_to_trim * 3\n",
    "    \n",
    "    # Calculate the adjusted start and end values for the untrimmed ORF\n",
    "    adj_start = start_from_raw_seq + orf_start\n",
    "    adj_end = end_from_raw_seq - (length_extracted - orf_end)\n",
    "    \n",
    "    # Adjust for trimming for appropriate strand.\n",
    "    if strand == 1:\n",
    "        adj_start += len_seq_trimmed\n",
    "        #adj_end += 3 # turns out stop codon is part of numbering biopython returns\n",
    "    elif strand == -1:\n",
    "        adj_end -= len_seq_trimmed\n",
    "        #adj_start -= 3 # turns out stop codon is part of numbering biopython returns\n",
    "    else:\n",
    "        sys.stderr.write(\"**ERROR**No strand match option detected!**ERROR**\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Collect the sequence for the actual gene encoding region from\n",
    "    # the original sequence. This way the original numbers will\n",
    "    # be put in the file.\n",
    "    start_n_end_str = \"{}-{}\".format(adj_start,adj_end)\n",
    "    %run extract_subsequence_from_FASTA.py {raw_seq_source_fn} {raw_seq_source_id} {start_n_end_str}\n",
    "    \n",
    "    # rename the extracted subsequence a more distinguishing name and notify\n",
    "    g_output_file_name = strain_id +\"_\" + gene_name + \"_ortholog_gene.fa\"\n",
    "    !mv {raw_seq_filen} {g_output_file_name} # because the sequence saved happens to \n",
    "    # be same as raw sequence file saved previously, that name can be used to\n",
    "    # rename new file.\n",
    "    gene_seqs_fn_list.append(g_output_file_name)\n",
    "    sys.stderr.write(\"\\n\\nRenamed gene file to \"\n",
    "                     \"`{}`.\".format(g_output_file_name))\n",
    "    \n",
    "    # Convert extracted sequence to reverse complement if translation was on negative strand.\n",
    "    if strand == -1:\n",
    "        %run convert_fasta_to_reverse_complement.py {g_output_file_name}\n",
    "        # replace original sequence file with the produced file\n",
    "        produced_fn = generate_rcoutput_file_name(g_output_file_name)\n",
    "        !mv {produced_fn} {g_output_file_name}\n",
    "        # add (after saved) onto the end of the description line for that `-1 strand` \n",
    "        # No way to do this in my current version of convert sequence. So editing descr line.\n",
    "        add_strand_to_description_line(g_output_file_name)\n",
    "\n",
    "    \n",
    "    #When settled on actual protein encoding sequence, fill out\n",
    "    # description to use for saving the protein sequence.\n",
    "    prot_descr =  (record.description.rsplit(\":\",1)[0]+ \" \"+ gene_name \n",
    "                   + \"_ortholog\"+ \"| \" +str(len(prot_seq)) + \" aas | from \" \n",
    "                   + raw_seq_source_id + \" \"\n",
    "                   + str(adj_start) + \"-\"+str(adj_end))\n",
    "    if strand == -1:\n",
    "        prot_descr += \"; {} strand\".format(strand)\n",
    "    \n",
    "    # save the protein sequence as FASTA\n",
    "    chunk_size = 60 #<---amino acids per line to have in FASTA\n",
    "    prot_seq_chunks = [prot_seq[i:i+chunk_size] for i in range(\n",
    "        0, len(prot_seq),chunk_size)]\n",
    "    prot_seq_fa = \">\" + prot_descr + \"\\n\"+ \"\\n\".join(prot_seq_chunks)\n",
    "    p_output_file_name = strain_id +\"_\" + gene_name + \"_protein_ortholog.fa\"\n",
    "    with open(p_output_file_name, 'w') as output:\n",
    "        output.write(prot_seq_fa)\n",
    "    prot_seqs_fn_list.append(p_output_file_name)\n",
    "    sys.stderr.write(\"\\n\\nProtein sequence saved as \"\n",
    "                     \"`{}`.\".format(p_output_file_name))\n",
    "    \n",
    "    \n",
    "    # at end store information in `prot_seqs_info` for later making a dataframe \n",
    "    # and then text table for saving summary\n",
    "    #'YPS138':['<source id>',<protein length>,-1,52,2626,'<gene file name>','<protein file name>']\n",
    "    prot_seqs_info[strain_id] = [raw_seq_source_id,len(prot_seq),strand,adj_start,adj_end,\n",
    "                                 g_output_file_name,p_output_file_name]\n",
    "    \n",
    "    sys.stderr.write(\"\\n******END OF A SET OF PROTEIN ORTHOLOG \"\n",
    "                     \"AND ENCODING GENE********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Text file of associated details saved as 'RPB1_orthologs_table.tsv'."
     ]
    }
   ],
   "source": [
    "# use `prot_seqs_info` for saving a summary text table (first convert to dataframe?)\n",
    "table_fn_prefix = gene_name + \"_orthologs_table\"\n",
    "table_fn = table_fn_prefix + \".tsv\"\n",
    "pkl_table_fn = table_fn_prefix + \".pkl\"\n",
    "import pandas as pd\n",
    "info_df = pd.DataFrame.from_dict(prot_seqs_info, orient='index',\n",
    "    columns=['descr_id', 'length', 'strand', 'start','end','gene_file','prot_file']) # based on\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html and\n",
    "# note from Python 3.6 that `pd.DataFrame.from_items` is deprecated; \n",
    "#\"Please use DataFrame.from_dict\"\n",
    "info_df.to_pickle(pkl_table_fn)\n",
    "info_df.to_csv(table_fn, sep='\\t') # keep index is default\n",
    "sys.stderr.write(\"Text file of associated details saved as '{}'.\".format(table_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected gene and protein sequences (plus table of details) gathered and saved as `RPB1_ortholog_seqs.tar.gz`."
     ]
    }
   ],
   "source": [
    "# pack up archive of gene and protein sequences plus the table\n",
    "seqs_list = gene_seqs_fn_list + prot_seqs_fn_list + [table_fn,pkl_table_fn]\n",
    "archive_file_name = gene_name+\"_ortholog_seqs.tar.gz\"\n",
    "!tar czf {archive_file_name} {\" \".join(seqs_list)} # use the list for archiving command\n",
    "sys.stderr.write(\"\\nCollected gene and protein sequences\"\n",
    "                 \" (plust table of details) gathered and saved as \"\n",
    "                 \"`{}`.\".format(archive_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tarballed archive to your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
