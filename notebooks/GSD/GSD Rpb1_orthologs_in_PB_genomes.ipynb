{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSD: Rpb1 orthologs in PB genomes\n",
    "\n",
    "This collects Rpb1 gene and protein sequences from a collection of PacBio sequenced yeast genomes from [Yue et al 2017](https://www.ncbi.nlm.nih.gov/pubmed/28416820), and then counts the heptad repeats. It builds on the notebook [Searching for coding sequences in genomes using BLAST and Python](notebooks/Searching%20for%20coding%20sequences%20in%20genomes%20using%20BLAST%20and%20Python.ipynb) and use of PatMatch along with Python, the basics of which I illustrated [here](https://github.com/fomightez/patmatch-binder).\n",
    "\n",
    "Reference for sequence data:  \n",
    "[Contrasting evolutionary genome dynamics between domesticated and wild yeasts.\n",
    "Yue JX, Li J, Aigrain L, Hallin J, Persson K, Oliver K, BergstrÃ¶m A, Coupland P, Warringer J, Lagomarsino MC, Fischer G, Durbin R, Liti G. Nat Genet. 2017 Jun;49(6):913-924. doi: 10.1038/ng.3847. Epub 2017 Apr 17. PMID: 28416820](https://www.ncbi.nlm.nih.gov/pubmed/28416820)\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Get scripts and sequence data necessary.\n",
    "\n",
    "**DO NOT 'RUN ALL'. AN INTERACTION IS NECESSARY AT CELL FOUR. AFTER THAT INTERACTION, THE REST BELOW IT CAN BE RUN.**\n",
    "\n",
    "(Caveat: right now this is written for genes with no introns. Only a few hundred have in yeast and that is the organism in this example. Intron presence would only become important when trying to translate in late stages of this workflow.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name = \"RPB1\"\n",
    "size_expected = 5202\n",
    "get_seq_from_link = False\n",
    "link_to_FASTA_of_gene = \"https://gist.githubusercontent.com/fomightez/f46b0624f1d8e3abb6ff908fc447e63b/raw/625eaba76bb54e16032f90c8812350441b753a0c/uz_S288C_YOR270C_VPH1_coding.fsa\"\n",
    "#**Possible future enhancement would be to add getting the FASTA of the gene from Yeastmine with just systematic id**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the genomes data, the `blast_to_df` script, and sequence to search for matches in the genomes by running these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13759  100 13759    0     0  85459      0 --:--:-- --:--:-- --:--:-- 85459\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2311      0 --:--:-- --:--:-- --:--:--  2311\n",
      "100 3687k  100 3687k    0     0  8052k      0 --:--:-- --:--:-- --:--:-- 33.8M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3560      0 --:--:-- --:--:-- --:--:--  3632\n",
      "100 3387k  100 3387k    0     0  12.2M      0 --:--:-- --:--:-- --:--:-- 12.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3560      0 --:--:-- --:--:-- --:--:--  3560\n",
      "100 3348k  100 3348k    0     0  12.8M      0 --:--:-- --:--:-- --:--:-- 12.8M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2342      0 --:--:-- --:--:-- --:--:--  2342\n",
      "100 3406k  100 3406k    0     0  11.6M      0 --:--:-- --:--:-- --:--:-- 17.1M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3178      0 --:--:-- --:--:-- --:--:--  3178\n",
      "100 3357k  100 3357k    0     0  13.0M      0 --:--:-- --:--:-- --:--:-- 13.0M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3423      0 --:--:-- --:--:-- --:--:--  3490\n",
      "100 3375k  100 3375k    0     0  12.8M      0 --:--:-- --:--:-- --:--:-- 12.8M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3122      0 --:--:-- --:--:-- --:--:--  3122\n",
      "100 3332k  100 3332k    0     0  12.1M      0 --:--:-- --:--:-- --:--:-- 29.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3490      0 --:--:-- --:--:-- --:--:--  3490\n",
      "100 3658k  100 3658k    0     0  12.5M      0 --:--:-- --:--:-- --:--:-- 12.5M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3560      0 --:--:-- --:--:-- --:--:--  3560\n",
      "100 3350k  100 3350k    0     0  13.2M      0 --:--:-- --:--:-- --:--:-- 13.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   2870      0 --:--:-- --:--:-- --:--:--  3178\n",
      "100 3349k  100 3349k    0     0  12.6M      0 --:--:-- --:--:-- --:--:-- 33.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3178      0 --:--:-- --:--:-- --:--:--  3178\n",
      "100 3701k  100 3701k    0     0  12.5M      0 --:--:-- --:--:-- --:--:-- 12.5M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   178  100   178    0     0   3708      0 --:--:-- --:--:-- --:--:--  3708\n",
      "100 3362k  100 3362k    0     0  13.3M      0 --:--:-- --:--:-- --:--:-- 13.3M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_needed = \"blast_to_df.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/blast-utilities/blast_to_df.py\n",
    "import pandas as pd\n",
    "# Prepare for getting PacBio (Yue et al 2017 sequences)\n",
    "#make a list of the strain designations\n",
    "yue_et_al_strains = [\"S288C\",\"DBVPG6044\",\"DBVPG6765\",\"SK1\",\"Y12\",\n",
    "                     \"YPS128\",\"UWOPS034614\",\"CBS432\",\"N44\",\"YPS138\",\n",
    "                     \"UFRJ50816\",\"UWOPS919171\"]\n",
    "# Get & unpack the genome sequences from strains \n",
    "for s in yue_et_al_strains:\n",
    "    !curl -LO http://yjx1217.github.io/Yeast_PacBio_2016/data/Nuclear_Genome/{s}.genome.fa.gz\n",
    "    !gunzip -f {s}.genome.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "S288C.genome.fa chromosome identifiers tagged.\n",
      "DBVPG6044.genome.fa chromosome identifiers tagged.\n",
      "DBVPG6765.genome.fa chromosome identifiers tagged.\n",
      "SK1.genome.fa chromosome identifiers tagged.\n",
      "Y12.genome.fa chromosome identifiers tagged.\n",
      "YPS128.genome.fa chromosome identifiers tagged.\n",
      "UWOPS034614.genome.fa chromosome identifiers tagged.\n",
      "CBS432.genome.fa chromosome identifiers tagged.\n",
      "N44.genome.fa chromosome identifiers tagged.\n",
      "YPS138.genome.fa chromosome identifiers tagged.\n",
      "UFRJ50816.genome.fa chromosome identifiers tagged.\n",
      "UWOPS919171.genome.fa chromosome identifiers tagged."
     ]
    }
   ],
   "source": [
    "# add identifiers to each `chr` so results for each strain clear later\n",
    "chromosome_id_prefix = \"chr\"\n",
    "def add_strain_id_to_description_line(file,strain_id):\n",
    "    '''\n",
    "    Takes a file and edits every description line to add \n",
    "    strain_id after the caret.\n",
    "    \n",
    "    Saves the fixed file\n",
    "    '''\n",
    "    import sys\n",
    "    output_file_name = \"temp.txt\"\n",
    "    # prepare output file for saving so it will be open and ready\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "\n",
    "        # read in the input file\n",
    "        with open(file, 'r') as input_handler:\n",
    "            # prepare to give feeback later or allow skipping to certain start\n",
    "            lines_processed = 0\n",
    "\n",
    "            for line in input_handler:\n",
    "                lines_processed += 1\n",
    "                if line.startswith(\">\"):\n",
    "                    rest_o_line = line.split(\">\")\n",
    "                    new_line = \">\"+strain_id + rest_o_line[1]\n",
    "                else:\n",
    "                    new_line = line\n",
    "                \n",
    "                # Send text to output\n",
    "                output_file.write(new_line)\n",
    "\n",
    "    \n",
    "    # replace the original file with edited\n",
    "    !mv temp.txt {file}\n",
    "    # Feedback\n",
    "    sys.stderr.write(\"\\n{} chromosome identifiers tagged.\".format(file))\n",
    "\n",
    "for s in yue_et_al_strains:\n",
    "    add_strain_id_to_description_line(s+\".genome.fa\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EDIT THE FILE 'RPB1.fsa' TO CONTAIN YOUR GENE OF INTEREST (FASTA-FORMATTED)."
     ]
    }
   ],
   "source": [
    "# Get SGD gene sequence in FASTA format to search for best matches in the genomes\n",
    "import sys\n",
    "gene_filen = gene_name + \".fsa\"\n",
    "if get_seq_from_link:\n",
    "    !curl -o {gene_filen} {link_to_FASTA_of_gene}\n",
    "else:\n",
    "    !touch {gene_filen}\n",
    "    sys.stderr.write(\"\\nEDIT THE FILE '{}' TO CONTAIN \"\n",
    "        \"YOUR GENE OF INTEREST (FASTA-FORMATTED)\"\n",
    "        \".\".format(gene_filen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I PUT CONTENTS OF FILE `S288C_YDL140C_RPO21_coding.fsa` downloaded from [here](https://www.yeastgenome.org/locus/S000002299/sequence) as 'RPB1.fsa'.**\n",
    "\n",
    "Now you are prepared to run BLAST to search each PacBio-sequenced genomes for the best match to a gene from the Saccharomyces cerevisiae strain S288C reference sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BLAST to search the genomes for matches to the gene in the reference genome at SGD\n",
    "\n",
    "SGD is the [Saccharomyces cerevisiae Genome Database site](http:yeastgenome.org) and the reference genome is from S288C.\n",
    "\n",
    "This is going to go through each genome and make a database so it is searchable and then search for matches to the gene. The information on the best match will be collected. One use for that information will be collecting the corresponding sequences later.\n",
    "\n",
    "Import the script that allows sending BLAST output to Python dataframes so that we can use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blast_to_df import blast_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DBVPG6044.genome.fa',\n",
       " 'DBVPG6765.genome.fa',\n",
       " 'CBS432.genome.fa',\n",
       " 'YPS128.genome.fa',\n",
       " 'UFRJ50816.genome.fa',\n",
       " 'S288C.genome.fa',\n",
       " 'SK1.genome.fa',\n",
       " 'UWOPS034614.genome.fa',\n",
       " 'UWOPS919171.genome.fa',\n",
       " 'YPS138.genome.fa',\n",
       " 'N44.genome.fa',\n",
       " 'Y12.genome.fa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of all `genome.fa` files, excluding `genome.fa.nhr` and `genome.fa.nin` and `genome.fansq`\n",
    "# The excluding was only necessary because I had run some queries preliminarily in development. Normally, it would just be the `.re.fa` at the outset.\n",
    "fn_to_check = \"genome.fa\" \n",
    "genomes = []\n",
    "import os\n",
    "import fnmatch\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, '*'+fn_to_check):\n",
    "        if not file.endswith(\".nhr\") and not file.endswith(\".nin\") and not file.endswith(\".nsq\") :\n",
    "            genomes.append(file)\n",
    "genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:45\n",
      "New DB name:   /home/jovyan/notebooks/GSD/DBVPG6044.genome.fa\n",
      "New DB title:  DBVPG6044.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.282062 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:46\n",
      "New DB name:   /home/jovyan/notebooks/GSD/DBVPG6765.genome.fa\n",
      "New DB title:  DBVPG6765.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.245767 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:48\n",
      "New DB name:   /home/jovyan/notebooks/GSD/CBS432.genome.fa\n",
      "New DB title:  CBS432.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.241637 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:50\n",
      "New DB name:   /home/jovyan/notebooks/GSD/YPS128.genome.fa\n",
      "New DB title:  YPS128.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.34221 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:51\n",
      "New DB name:   /home/jovyan/notebooks/GSD/UFRJ50816.genome.fa\n",
      "New DB title:  UFRJ50816.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.283168 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:53\n",
      "New DB name:   /home/jovyan/notebooks/GSD/S288C.genome.fa\n",
      "New DB title:  S288C.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.256124 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:54\n",
      "New DB name:   /home/jovyan/notebooks/GSD/SK1.genome.fa\n",
      "New DB title:  SK1.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.299404 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:55\n",
      "New DB name:   /home/jovyan/notebooks/GSD/UWOPS034614.genome.fa\n",
      "New DB title:  UWOPS034614.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.256635 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:57\n",
      "New DB name:   /home/jovyan/notebooks/GSD/UWOPS919171.genome.fa\n",
      "New DB title:  UWOPS919171.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.260651 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:58\n",
      "New DB name:   /home/jovyan/notebooks/GSD/YPS138.genome.fa\n",
      "New DB title:  YPS138.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.251668 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:52:59\n",
      "New DB name:   /home/jovyan/notebooks/GSD/N44.genome.fa\n",
      "New DB title:  N44.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.259337 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 01/02/2019 19:53:01\n",
      "New DB name:   /home/jovyan/notebooks/GSD/Y12.genome.fa\n",
      "New DB title:  Y12.genome.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 16 sequences in 0.22137 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided results read and converted to a dataframe...\n",
      "\n",
      "A dataframe of the data has been saved as a file\n",
      "in a manner where other Python programs can access it (pickled form).\n",
      "RESULTING DATAFRAME is stored as ==> 'BLAST_pickled_df.pkl'\n",
      "\n",
      "Returning a dataframe with the information as well."
     ]
    }
   ],
   "source": [
    "SGD_gene = gene_filen\n",
    "dfs = []\n",
    "for genome in genomes:\n",
    "    !makeblastdb -in {genome} -dbtype nucl\n",
    "    result = !blastn -query {SGD_gene} -db {genome} -outfmt \"6 qseqid sseqid stitle pident qcovs length mismatch gapopen qstart qend sstart send qframe sframe frames evalue bitscore qseq sseq\"\n",
    "    from blast_to_df import blast_to_df\n",
    "    blast_df = blast_to_df(result.n)\n",
    "    dfs.append(blast_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes in the list `dfs` into one dataframe\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the df\n",
    "filen_prefix = gene_name + \"_orthologBLASTdf\"\n",
    "df.to_pickle(filen_prefix+\".pkl\")\n",
    "df.to_csv(filen_prefix+'.tsv', sep='\\t',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qseqid</th>\n",
       "      <th>sseqid</th>\n",
       "      <th>stitle</th>\n",
       "      <th>pident</th>\n",
       "      <th>qcovs</th>\n",
       "      <th>length</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gapopen</th>\n",
       "      <th>qstart</th>\n",
       "      <th>qend</th>\n",
       "      <th>sstart</th>\n",
       "      <th>send</th>\n",
       "      <th>qframe</th>\n",
       "      <th>sframe</th>\n",
       "      <th>frames</th>\n",
       "      <th>evalue</th>\n",
       "      <th>bitscore</th>\n",
       "      <th>qseq</th>\n",
       "      <th>sseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>DBVPG6044chrIV</td>\n",
       "      <td>DBVPG6044chrIV</td>\n",
       "      <td>99.020</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>216501</td>\n",
       "      <td>211321</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>DBVPG6765chrIV</td>\n",
       "      <td>DBVPG6765chrIV</td>\n",
       "      <td>99.885</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>211477</td>\n",
       "      <td>206276</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9574</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>CBS432chrIV</td>\n",
       "      <td>CBS432chrIV</td>\n",
       "      <td>92.522</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>211739</td>\n",
       "      <td>206559</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7432</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGTCAACAGTATTCGAGTGCTCCACTCCGTACAGTGAAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>YPS128chrIV</td>\n",
       "      <td>YPS128chrIV</td>\n",
       "      <td>99.923</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>210086</td>\n",
       "      <td>204885</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9585</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>92.368</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>355</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>213091</td>\n",
       "      <td>207932</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7369</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>S288CchrIV</td>\n",
       "      <td>S288CchrIV</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>210502</td>\n",
       "      <td>205301</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9607</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>SK1chrIV</td>\n",
       "      <td>SK1chrIV</td>\n",
       "      <td>99.020</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>222692</td>\n",
       "      <td>217512</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9304</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>UWOPS034614chrIV</td>\n",
       "      <td>UWOPS034614chrIV</td>\n",
       "      <td>99.500</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>209007</td>\n",
       "      <td>203827</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9443</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>UWOPS919171chrIV</td>\n",
       "      <td>UWOPS919171chrIV</td>\n",
       "      <td>92.272</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>219693</td>\n",
       "      <td>214492</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7380</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>YPS138chrIV</td>\n",
       "      <td>YPS138chrIV</td>\n",
       "      <td>92.695</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>211802</td>\n",
       "      <td>206622</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7481</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>N44chrIV</td>\n",
       "      <td>N44chrIV</td>\n",
       "      <td>93.195</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>212185</td>\n",
       "      <td>207005</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7625</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGTCAACAGTATTCGAGTGCTCCACTCCGTACAGTGAAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RPO21</td>\n",
       "      <td>Y12chrIV</td>\n",
       "      <td>Y12chrIV</td>\n",
       "      <td>99.923</td>\n",
       "      <td>100</td>\n",
       "      <td>5202</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5202</td>\n",
       "      <td>211561</td>\n",
       "      <td>206360</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1/-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9585</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "      <td>ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qseqid            sseqid            stitle   pident  qcovs  length  \\\n",
       "0  RPO21    DBVPG6044chrIV    DBVPG6044chrIV   99.020    100    5202   \n",
       "0  RPO21    DBVPG6765chrIV    DBVPG6765chrIV   99.885    100    5202   \n",
       "0  RPO21       CBS432chrIV       CBS432chrIV   92.522    100    5202   \n",
       "0  RPO21       YPS128chrIV       YPS128chrIV   99.923    100    5202   \n",
       "0  RPO21    UFRJ50816chrXI    UFRJ50816chrXI   92.368    100    5202   \n",
       "0  RPO21        S288CchrIV        S288CchrIV  100.000    100    5202   \n",
       "0  RPO21          SK1chrIV          SK1chrIV   99.020    100    5202   \n",
       "0  RPO21  UWOPS034614chrIV  UWOPS034614chrIV   99.500    100    5202   \n",
       "0  RPO21  UWOPS919171chrIV  UWOPS919171chrIV   92.272    100    5202   \n",
       "0  RPO21       YPS138chrIV       YPS138chrIV   92.695    100    5202   \n",
       "0  RPO21          N44chrIV          N44chrIV   93.195    100    5202   \n",
       "0  RPO21          Y12chrIV          Y12chrIV   99.923    100    5202   \n",
       "\n",
       "   mismatch  gapopen  qstart  qend  sstart    send  qframe  sframe frames  \\\n",
       "0        30       11       1  5202  216501  211321       1      -1   1/-1   \n",
       "0         6        0       1  5202  211477  206276       1      -1   1/-1   \n",
       "0       368        1       1  5202  211739  206559       1      -1   1/-1   \n",
       "0         4        0       1  5202  210086  204885       1      -1   1/-1   \n",
       "0       355        9       1  5202  213091  207932       1      -1   1/-1   \n",
       "0         0        0       1  5202  210502  205301       1      -1   1/-1   \n",
       "0        30       11       1  5202  222692  217512       1      -1   1/-1   \n",
       "0         5        1       1  5202  209007  203827       1      -1   1/-1   \n",
       "0       402        0       1  5202  219693  214492       1      -1   1/-1   \n",
       "0       359        1       1  5202  211802  206622       1      -1   1/-1   \n",
       "0       333        1       1  5202  212185  207005       1      -1   1/-1   \n",
       "0         4        0       1  5202  211561  206360       1      -1   1/-1   \n",
       "\n",
       "   evalue  bitscore                                               qseq  \\\n",
       "0     0.0      9304  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9574  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7432  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9585  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7369  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9607  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9304  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9443  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7380  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7481  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      7625  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "0     0.0      9585  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...   \n",
       "\n",
       "                                                sseq  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGTCAACAGTATTCGAGTGCTCCACTCCGTACAGTGAAGG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...  \n",
       "0  ATGGTAGGACAACAGTATTCGAGTGCTCCGCTCCGTACAGTGAAAG...  \n",
       "0  ATGGTAGGTCAACAGTATTCGAGTGCTCCACTCCGTACAGTGAAGG...  \n",
       "0  ATGGTAGGACAACAGTATTCTAGTGCTCCACTCCGTACAGTAAAAG...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computationally check if any genomes missing from the BLAST results list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: 12\n",
      "results: 12\n",
      "missing: 0\n"
     ]
    }
   ],
   "source": [
    "subjids = df.sseqid.tolist()\n",
    "#print (subjids)\n",
    "#print (subjids[0:10])\n",
    "subjids = [x.split(chromosome_id_prefix)[0] for x in subjids]\n",
    "#print (subjids)\n",
    "#print (subjids[0:10])\n",
    "len_genome_fn_end = len(fn_to_check) + 1 # plus one to accound for the period that will be \n",
    "# between `fn_to_check` and strain_id`, such as `SK1.genome.fa`\n",
    "genome_ids = [x[:-len_genome_fn_end] for x in genomes]\n",
    "#print (genome_ids[0:10])\n",
    "\n",
    "a = set(genome_ids)\n",
    "#print (a)\n",
    "print (\"initial:\",len(a))\n",
    "r = set(subjids)\n",
    "print(\"results:\",len(r))\n",
    "print (\"missing:\",len(a-r))\n",
    "#a - r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: Report on how expected size compares to max size seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected size of gene: 5202\n",
      "Most frequent size of matches: 5202\n",
      "Maximum size of matches: 5202\n"
     ]
    }
   ],
   "source": [
    "size_seen = df.length.max(0)\n",
    "print (\"Expected size of gene:\", size_expected)\n",
    "print (\"Most frequent size of matches:\", df.length.mode()[0])\n",
    "print (\"Maximum size of matches:\", df.length.max(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the identified, raw sequences\n",
    "\n",
    "Get the expected size centered on the best match, plus a little flanking each because they might not exactly cover the entire open reading frame. (Although, the example here all look to be full size.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16612  100 16612    0     0   117k      0 --:--:-- --:--:-- --:--:--  117k\n",
      "Collecting pyfaidx\n",
      "  Downloading https://files.pythonhosted.org/packages/75/a5/7e2569527b3849ea28d79b4f70d7cf46a47d36459bc59e0efa4e10e8c8b2/pyfaidx-0.5.5.2.tar.gz\n",
      "Requirement already satisfied: six in /srv/conda/lib/python3.6/site-packages (from pyfaidx) (1.12.0)\n",
      "Requirement already satisfied: setuptools>=0.7 in /srv/conda/lib/python3.6/site-packages (from pyfaidx) (40.6.3)\n",
      "Building wheels for collected packages: pyfaidx\n",
      "  Running setup.py bdist_wheel for pyfaidx ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/54/a2/b4/e242e58d23b2808e191b214067880faa46cd2341f363886e0b\n",
      "Successfully built pyfaidx\n",
      "Installing collected packages: pyfaidx\n",
      "Successfully installed pyfaidx-0.5.5.2\n"
     ]
    }
   ],
   "source": [
    "# Get the script for extracting based on position (and install dependency pyfaidx)\n",
    "import os\n",
    "file_needed = \"extract_regions_from_clustal_alignment.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/Extract_from_FASTA/extract_subsequence_from_FASTA.py\n",
    "!pip install pyfaidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6044chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6765chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedCBS432chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS128chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUFRJ50816chrXI.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedS288CchrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedSK1chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS034614chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS919171chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS138chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedN44chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedY12chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Collected RAW sequences gathered and saved as `RPB1_raw_ortholog_seqs.tar.gz`."
     ]
    }
   ],
   "source": [
    "size_expected = size_expected # use value from above, or alter at this point.\n",
    "#size_expected = df.length.max(0) #bp length of SGD coding sequence; should be equivalent and that way not hardcoded?\n",
    "extra_add_to_start = 51 #to allow for 'fuzziness' at starting end\n",
    "extra_add_to_end = 51 #to allow for 'fuzziness' at far end\n",
    "genome_fn_end = \"genome.fa\" \n",
    "\n",
    "\n",
    "def midpoint(items):\n",
    "    '''\n",
    "    takes a iterable of items and returns the midpoint (integer) of the first \n",
    "    and second values\n",
    "    '''\n",
    "    return int((int(items[0])+int(items[1]))/2)\n",
    "\n",
    "#midpoint((1,100))\n",
    "\n",
    "def determine_pos_to_get(match_start,match_end):\n",
    "    '''\n",
    "    Take the start and end of the matched region.\n",
    "    \n",
    "    Calculate midpoint between those and then \n",
    "    center expected size on that to determine\n",
    "    preliminary start and preliminary end to get.\n",
    "    Add the extra basepairs to get at each end\n",
    "    to allow for fuzziness/differences of actual\n",
    "    gene ends for orthologs. \n",
    "    Return the final start and end positions to get.\n",
    "    \n",
    "    '''\n",
    "    center_of_match = midpoint((match_start,match_end))\n",
    "    half_size_expected = int(size_expected/2.0)\n",
    "    if size_expected % 2 != 0:\n",
    "        half_size_expected += 1\n",
    "    start_pos = center_of_match - half_size_expected\n",
    "    end_pos = center_of_match + half_size_expected\n",
    "    start_pos -= extra_add_to_start\n",
    "    end_pos += extra_add_to_end \n",
    "    \n",
    "    # Because of getting some flanking sequences to account for 'fuzziness', it \n",
    "    # is possible the start and end can exceed possible. 'End' is not a problem \n",
    "    # because the `extract_subsequence_from_FASTA.py` script will get as much as\n",
    "    # it from the indicated sequence if a larger than possible number is \n",
    "    # provided. However,'start' can become negative and because the region to \n",
    "    # extract is provided as a string the dash can become a problem. Dealing \n",
    "    # with it here by making sequence positive only.\n",
    "    if start_pos < 0:\n",
    "            start_pos = 1\n",
    "        \n",
    "    return start_pos, end_pos\n",
    "\n",
    "\n",
    "# go through the dataframe using information on each to come up with sequence file, \n",
    "# specific indentifier within sequence file, and the start and end to extract\n",
    "# store these valaues as a list in a dictionary with the strain identifier as the key.\n",
    "extracted_info = {}\n",
    "start,end = 0,0\n",
    "for row in df.itertuples():\n",
    "    #print (row.length)\n",
    "    start_to_get, end_to_get = determine_pos_to_get(row.sstart, row.send)\n",
    "    posns_to_get = \"{}-{}\".format(start_to_get, end_to_get)\n",
    "    record_id = row.sseqid\n",
    "    strain_id = row.sseqid.split(chromosome_id_prefix)[0]\n",
    "    seq_fn = strain_id + \".\" + genome_fn_end\n",
    "    extracted_info[strain_id] = [seq_fn, record_id, posns_to_get]\n",
    "# Use the dictionary to get the sequences\n",
    "for id_ in extracted_info:\n",
    "    #%run extract_subsequence_from_FASTA.py {*extracted_info[id_]} #unpacking doesn't seem to work here in `%run`\n",
    "    %run extract_subsequence_from_FASTA.py {extracted_info[id_][0]} {extracted_info[id_][1]} {extracted_info[id_][2]}\n",
    "\n",
    "#package up the retrieved sequences\n",
    "archive_file_name = gene_name+\"_raw_ortholog_seqs.tar.gz\"\n",
    "# make list of extracted files using fnmatch\n",
    "fn_part_to_match = \"seq_extracted\"\n",
    "collected_seq_files_list = []\n",
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, fn_part_to_match+'*'):\n",
    "        #print (file)\n",
    "        collected_seq_files_list.append(file)\n",
    "!tar czf {archive_file_name} {\" \".join(collected_seq_files_list)} # use the list for archiving command\n",
    "sys.stderr.write(\"\\n\\nCollected RAW sequences gathered and saved as \"\n",
    "                 \"`{}`.\".format(archive_file_name))\n",
    "# move the collected raw sequences to a folder in preparation for\n",
    "# extracting encoding sequence from original source below\n",
    "!mkdir raw\n",
    "!mv seq_extracted*.fa raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That archive should contain the \"raw\" sequence for each gene, even if the ends are a little different for each. At minimum the entire gene sequence needs to be there at this point; extra at each end is preferable at this point.\n",
    "\n",
    "You should inspect them as soon as possible and adjust the extra sequence to add higher or lower depending on whether the ortholog genes vary more or less, respectively. The reason they don't need to be perfect yet though is because next we are going to extract the longest open reading frame, which presumably demarcates the entire gene. Then we can return to use that information to clean up the collected sequences to just be the coding sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect protein translations of the genes and then clean up \"raw\" sequences to just be coding\n",
    "\n",
    "We'll assume the longest translatable frame in the collected \"raw\" sequences encodes the protein sequence for the gene orthologs of interest. Well base these steps on the [section '20.1.13  Identifying open reading frames'](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc299) in the present version of the [Biopython Tutorial and Cookbook](http://biopython.org/DIST/docs/tutorial/Tutorial.html) (Last Update â 18 December 2018 (Biopython 1.73)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(First run the next cell to get a script needed for dealing with the strand during the translation and gathering of thge encoding sequence.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8851  100  8851    0     0  66052      0 --:--:-- --:--:-- --:--:-- 66052\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_needed = \"convert_fasta_to_reverse_complement.py\"\n",
    "if not os.path.isfile(file_needed):\n",
    "    !curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/ConvertSeq/convert_fasta_to_reverse_complement.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to perform the work described in the header to this section..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/Bio/Seq.py:2576: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  BiopythonWarning)\n",
      "\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6044chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `DBVPG6044_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'DBVPG6044_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'DBVPG6044_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In DBVPG6044_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `DBVPG6044_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedS288CchrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `S288C_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'S288C_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'S288C_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In S288C_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `S288C_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS138chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `YPS138_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'YPS138_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'YPS138_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In YPS138_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `YPS138_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS034614chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UWOPS034614_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UWOPS034614_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UWOPS034614_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UWOPS034614_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UWOPS034614_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedDBVPG6765chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `DBVPG6765_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'DBVPG6765_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'DBVPG6765_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In DBVPG6765_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `DBVPG6765_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedYPS128chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `YPS128_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'YPS128_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'YPS128_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In YPS128_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `YPS128_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedSK1chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `SK1_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'SK1_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'SK1_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In SK1_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `SK1_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedCBS432chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `CBS432_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'CBS432_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'CBS432_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In CBS432_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `CBS432_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUWOPS919171chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UWOPS919171_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UWOPS919171_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UWOPS919171_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UWOPS919171_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UWOPS919171_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedUFRJ50816chrXI.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `UFRJ50816_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'UFRJ50816_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'UFRJ50816_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In UFRJ50816_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `UFRJ50816_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedY12chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `Y12_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'Y12_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'Y12_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In Y12_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `Y12_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********\n",
      "\n",
      "*****************DONE**************************\n",
      "Extracted sequence saved in FASTA format as 'seq_extractedN44chrIV.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "\n",
      "Renamed gene file to `N44_RPB1_ortholog_gene.fa`.\n",
      "\n",
      "*****************DONE**************************\n",
      "Sequences in FASTA file 'N44_RPB1_ortholog_gene.fa' converted to reverse complement\n",
      "and saved as 'N44_RPB1_ortholog_gene_rc.fa'.\n",
      "*****************DONE**************************\n",
      "\n",
      "In N44_RPB1_ortholog_gene.fa, strand noted.\n",
      "\n",
      "Protein sequence saved as `N44_RPB1_protein_ortholog.fa`.\n",
      "******END OF A SET OF PROTEIN ORTHOLOG AND ENCODING GENE********"
     ]
    }
   ],
   "source": [
    "# find the featured open reading frame and collect presumed protein sequences\n",
    "# Collect the corresponding encoding sequence from the original source\n",
    "def len_ORF(items):\n",
    "    # orf is fourth item in the tuples\n",
    "    return len(items[3])\n",
    "def find_orfs_with_trans(seq, trans_table, min_protein_length):\n",
    "    '''\n",
    "    adapted from the present section '20.1.13  Identifying open reading frames'\n",
    "    http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc299 in the \n",
    "    present version of the [Biopython Tutorial and Cookbook at \n",
    "    http://biopython.org/DIST/docs/tutorial/Tutorial.html \n",
    "    (Last Update â 18 December 2018 (Biopython 1.73)\n",
    "    Same as there except altered to sort on the length of the\n",
    "    open reading frame.\n",
    "    '''\n",
    "    answer = []\n",
    "    seq_len = len(seq)\n",
    "    for strand, nuc in [(+1, seq), (-1, seq.reverse_complement())]:\n",
    "        for frame in range(3):\n",
    "            trans = str(nuc[frame:].translate(trans_table))\n",
    "            trans_len = len(trans)\n",
    "            aa_start = 0\n",
    "            aa_end = 0\n",
    "            while aa_start < trans_len:\n",
    "                aa_end = trans.find(\"*\", aa_start)\n",
    "                if aa_end == -1:\n",
    "                    aa_end = trans_len\n",
    "                if aa_end-aa_start >= min_protein_length:\n",
    "                    if strand == 1:\n",
    "                        start = frame+aa_start*3\n",
    "                        end = min(seq_len,frame+aa_end*3+3)\n",
    "                    else:\n",
    "                        start = seq_len-frame-aa_end*3-3\n",
    "                        end = seq_len-frame-aa_start*3\n",
    "                    answer.append((start, end, strand,\n",
    "                                   trans[aa_start:aa_end]))\n",
    "                aa_start = aa_end+1\n",
    "    answer.sort(key=len_ORF, reverse = True)\n",
    "    return answer\n",
    "\n",
    "def generate_rcoutput_file_name(file_name,suffix_for_saving = \"_rc\"):\n",
    "    '''\n",
    "    from https://github.com/fomightez/sequencework/blob/master/ConvertSeq/convert_fasta_to_reverse_complement.py\n",
    "    Takes a file name as an argument and returns string for the name of the\n",
    "    output file. The generated name is based on the original file\n",
    "    name.\n",
    "    Specific example\n",
    "    =================\n",
    "    Calling function with\n",
    "        (\"sequence.fa\", \"_rc\")\n",
    "    returns\n",
    "        \"sequence_rc.fa\"\n",
    "    '''\n",
    "    main_part_of_name, file_extension = os.path.splitext(\n",
    "        file_name) #from \n",
    "    #http://stackoverflow.com/questions/541390/extracting-extension-from-filename-in-python\n",
    "    if '.' in file_name:  #I don't know if this is needed with the os.path.splitext method but I had it before so left it\n",
    "        return main_part_of_name + suffix_for_saving  + file_extension\n",
    "    else:\n",
    "        return file_name + suffix_for_saving + \".fa\"\n",
    "    \n",
    "def add_strand_to_description_line(file,strand=\"-1\"):\n",
    "    '''\n",
    "    Takes a file and edits description line to add \n",
    "    strand info at end.\n",
    "    \n",
    "    Saves the fixed file\n",
    "    '''\n",
    "    import sys\n",
    "    output_file_name = \"temp.txt\"\n",
    "    # prepare output file for saving so it will be open and ready\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "\n",
    "        # read in the input file\n",
    "        with open(file, 'r') as input_handler:\n",
    "            # prepare to give feeback later or allow skipping to certain start\n",
    "            lines_processed = 0\n",
    "\n",
    "            for line in input_handler:\n",
    "                lines_processed += 1\n",
    "                if line.startswith(\">\"):\n",
    "                    new_line = line.strip() + \"; {} strand\\n\".format(strand)\n",
    "                else:\n",
    "                    new_line = line\n",
    "                \n",
    "                # Send text to output\n",
    "                output_file.write(new_line)\n",
    "\n",
    "    \n",
    "    # replace the original file with edited\n",
    "    !mv temp.txt {file}\n",
    "    # Feedback\n",
    "    sys.stderr.write(\"\\nIn {}, strand noted.\".format(file))\n",
    "\n",
    "table = 1 #sets translation table to standard nuclear, see \n",
    "# https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi\n",
    "min_pro_len = 80 #cookbook had the standard `100`. Feel free to adjust.\n",
    "prot_seqs_info = {} #collect as dictionary with strain_id as key. Values to\n",
    "# be list with source id as first item and protein length as second and \n",
    "# strand in source seq as third item, and start and end in source sequence as fourth and fifth,\n",
    "# and file name of protein and gene as sixth and seventh.\n",
    "# Example key and value pair: 'YPS138':['<source id>','<protein length>',-1,52,2626,'<gene file name>','<protein file name>']\n",
    "gene_seqs_fn_list = []\n",
    "prot_seqs_fn_list = []\n",
    "from Bio import SeqIO\n",
    "for raw_seq_filen in collected_seq_files_list:\n",
    "    #strain_id = raw_seq_filen[:-len_genome_fn_end] #if was dealing with source seq\n",
    "    strain_id = raw_seq_filen.split(chromosome_id_prefix)[0].split(\"seq_extracted\")[1]\n",
    "    record = SeqIO.read(\"raw/\"+raw_seq_filen,\"fasta\")\n",
    "    raw_seq_source_fn = strain_id + \".\" + genome_fn_end\n",
    "    raw_seq_source_id = record.description.split(\":\")[0]\n",
    "    orf_list = find_orfs_with_trans(record.seq, table, min_pro_len)\n",
    "    orf_start, orf_end, strand, prot_seq = orf_list[0] #longest ORF seq for protein coding\n",
    "    \n",
    "    location_raw_seq = record.description.rsplit(\":\",1)[1] #get to use in calculating\n",
    "    # the start and end position in original genome sequence.\n",
    "    raw_loc_parts = location_raw_seq.split(\"-\")\n",
    "    start_from_raw_seq = int(raw_loc_parts[0])\n",
    "    end_from_raw_seq = int(raw_loc_parts[1])\n",
    "    length_extracted = len(record) #also to use in calculating relative original\n",
    "    \n",
    "    # Trim back to the first Methionine, assumed to be the initiating MET.\n",
    "    # (THIS MIGHT BE A SOURCE OF EXTRA 'LEADING' RESIDUES IN SOME CASES & ARGUES \n",
    "    # FOR LIMITING THE AMOUNT OF FLANKING SEQUENCE ADDED TO ALLOW FOR FUZINESS.)\n",
    "    try:\n",
    "        amt_resi_to_trim = prot_seq.index(\"M\")\n",
    "    except ValueError:\n",
    "        sys.stderr.write(\"**ERROR**When searching for initiating methionine,\\n\"\n",
    "                         \"no Methionine found in the traslated protein sequence.**ERROR**\")\n",
    "        sys.exit(1)\n",
    "    prot_seq = prot_seq[amt_resi_to_trim:]\n",
    "    len_seq_trimmed = amt_resi_to_trim * 3\n",
    "    \n",
    "    # Calculate the adjusted start and end values for the untrimmed ORF\n",
    "    adj_start = start_from_raw_seq + orf_start\n",
    "    adj_end = end_from_raw_seq - (length_extracted - orf_end)\n",
    "    \n",
    "    # Adjust for trimming for appropriate strand.\n",
    "    if strand == 1:\n",
    "        adj_start += len_seq_trimmed\n",
    "        #adj_end += 3 # turns out stop codon is part of numbering biopython returns\n",
    "    elif strand == -1:\n",
    "        adj_end -= len_seq_trimmed\n",
    "        #adj_start -= 3 # turns out stop codon is part of numbering biopython returns\n",
    "    else:\n",
    "        sys.stderr.write(\"**ERROR**No strand match option detected!**ERROR**\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Collect the sequence for the actual gene encoding region from\n",
    "    # the original sequence. This way the original numbers will\n",
    "    # be put in the file.\n",
    "    start_n_end_str = \"{}-{}\".format(adj_start,adj_end)\n",
    "    %run extract_subsequence_from_FASTA.py {raw_seq_source_fn} {raw_seq_source_id} {start_n_end_str}\n",
    "    \n",
    "    # rename the extracted subsequence a more distinguishing name and notify\n",
    "    g_output_file_name = strain_id +\"_\" + gene_name + \"_ortholog_gene.fa\"\n",
    "    !mv {raw_seq_filen} {g_output_file_name} # because the sequence saved happens to \n",
    "    # be same as raw sequence file saved previously, that name can be used to\n",
    "    # rename new file.\n",
    "    gene_seqs_fn_list.append(g_output_file_name)\n",
    "    sys.stderr.write(\"\\n\\nRenamed gene file to \"\n",
    "                     \"`{}`.\".format(g_output_file_name))\n",
    "    \n",
    "    # Convert extracted sequence to reverse complement if translation was on negative strand.\n",
    "    if strand == -1:\n",
    "        %run convert_fasta_to_reverse_complement.py {g_output_file_name}\n",
    "        # replace original sequence file with the produced file\n",
    "        produced_fn = generate_rcoutput_file_name(g_output_file_name)\n",
    "        !mv {produced_fn} {g_output_file_name}\n",
    "        # add (after saved) onto the end of the description line for that `-1 strand` \n",
    "        # No way to do this in my current version of convert sequence. So editing descr line.\n",
    "        add_strand_to_description_line(g_output_file_name)\n",
    "\n",
    "    \n",
    "    #When settled on actual protein encoding sequence, fill out\n",
    "    # description to use for saving the protein sequence.\n",
    "    prot_descr =  (record.description.rsplit(\":\",1)[0]+ \" \"+ gene_name \n",
    "                   + \"_ortholog\"+ \"| \" +str(len(prot_seq)) + \" aas | from \" \n",
    "                   + raw_seq_source_id + \" \"\n",
    "                   + str(adj_start) + \"-\"+str(adj_end))\n",
    "    if strand == -1:\n",
    "        prot_descr += \"; {} strand\".format(strand)\n",
    "    \n",
    "    # save the protein sequence as FASTA\n",
    "    chunk_size = 70 #<---amino acids per line to have in FASTA\n",
    "    prot_seq_chunks = [prot_seq[i:i+chunk_size] for i in range(\n",
    "        0, len(prot_seq),chunk_size)]\n",
    "    prot_seq_fa = \">\" + prot_descr + \"\\n\"+ \"\\n\".join(prot_seq_chunks)\n",
    "    p_output_file_name = strain_id +\"_\" + gene_name + \"_protein_ortholog.fa\"\n",
    "    with open(p_output_file_name, 'w') as output:\n",
    "        output.write(prot_seq_fa)\n",
    "    prot_seqs_fn_list.append(p_output_file_name)\n",
    "    sys.stderr.write(\"\\n\\nProtein sequence saved as \"\n",
    "                     \"`{}`.\".format(p_output_file_name))\n",
    "    \n",
    "    \n",
    "    # at end store information in `prot_seqs_info` for later making a dataframe \n",
    "    # and then text table for saving summary\n",
    "    #'YPS138':['<source id>',<protein length>,-1,52,2626,'<gene file name>','<protein file name>']\n",
    "    prot_seqs_info[strain_id] = [raw_seq_source_id,len(prot_seq),strand,adj_start,adj_end,\n",
    "                                 g_output_file_name,p_output_file_name]\n",
    "    \n",
    "    sys.stderr.write(\"\\n******END OF A SET OF PROTEIN ORTHOLOG \"\n",
    "                     \"AND ENCODING GENE********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Text file of associated details saved as 'RPB1_orthologs_table.tsv'."
     ]
    }
   ],
   "source": [
    "# use `prot_seqs_info` for saving a summary text table (first convert to dataframe?)\n",
    "table_fn_prefix = gene_name + \"_orthologs_table\"\n",
    "table_fn = table_fn_prefix + \".tsv\"\n",
    "pkl_table_fn = table_fn_prefix + \".pkl\"\n",
    "import pandas as pd\n",
    "info_df = pd.DataFrame.from_dict(prot_seqs_info, orient='index',\n",
    "    columns=['descr_id', 'length', 'strand', 'start','end','gene_file','prot_file']) # based on\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html and\n",
    "# note from Python 3.6 that `pd.DataFrame.from_items` is deprecated; \n",
    "#\"Please use DataFrame.from_dict\"\n",
    "info_df.to_pickle(pkl_table_fn)\n",
    "info_df.to_csv(table_fn, sep='\\t') # keep index is default\n",
    "sys.stderr.write(\"Text file of associated details saved as '{}'.\".format(table_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected gene and protein sequences (plus table of details) gathered and saved as `RPB1_ortholog_seqs.tar.gz`."
     ]
    }
   ],
   "source": [
    "# pack up archive of gene and protein sequences plus the table\n",
    "seqs_list = gene_seqs_fn_list + prot_seqs_fn_list + [table_fn,pkl_table_fn]\n",
    "archive_file_name = gene_name+\"_ortholog_seqs.tar.gz\"\n",
    "!tar czf {archive_file_name} {\" \".join(seqs_list)} # use the list for archiving command\n",
    "sys.stderr.write(\"\\nCollected gene and protein sequences\"\n",
    "                 \" (plus table of details) gathered and saved as \"\n",
    "                 \"`{}`.\".format(archive_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tarballed archive to your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the heptad repeats\n",
    "\n",
    "Make a table of the heptad repeats for each orthlogous protein sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 18722  100 18722    0     0   127k      0 --:--:-- --:--:-- --:--:--  127k\n"
     ]
    }
   ],
   "source": [
    "# get the 'patmatch results to dataframe' script\n",
    "!curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/patmatch-utilities/patmatch_results_to_df.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trick of putting `%%capture` on first line from [here](https://stackoverflow.com/a/23692951/8508004) to suppress the output from `patmatch_results_to_df` function from filling up cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 409 ms, sys: 124 ms, total: 533 ms\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "# Go through each protein sequence file and look for matches to heptad pattern\n",
    "\n",
    "# LATER POSSIBLE IMPROVEMENT. Translate pasted gene sequence and add SGD REF S228C as first in list `prot_seqs_fn_list`. Because \n",
    "# although this set of orthologs includes essentially S228C, other lists won't and best to have reference for comparing.\n",
    "\n",
    "\n",
    "heptad_pattern = \"[YF]SP[TG]SP[STAGN]\" # will catch repats#2 through #26 of S288C according to Corden, 2013 PMID: 24040939\n",
    "\n",
    "from patmatch_results_to_df import patmatch_results_to_df\n",
    "sum_dfs = []\n",
    "raw_dfs = []\n",
    "for prot_seq_fn in prot_seqs_fn_list:\n",
    "    !perl ../../patmatch_1.2/unjustify_fasta.pl {prot_seq_fn}\n",
    "    output = !perl ../../patmatch_1.2/patmatch.pl -p {heptad_pattern} {prot_seq_fn}.prepared\n",
    "    os.remove(os.path.join(prot_seq_fn+\".prepared\")) #delete file made for PatMatch\n",
    "    raw_pm_df = patmatch_results_to_df(output.n, pattern=heptad_pattern, name=\"CTD_heptad\")\n",
    "    raw_pm_df.sort_values('hit_number', ascending=False, inplace=True)\n",
    "    sum_dfs.append(raw_pm_df.groupby('FASTA_id').head(1))\n",
    "    raw_dfs.append(raw_pm_df)\n",
    "sum_pm_df = pd.concat(sum_dfs, ignore_index=True)\n",
    "sum_pm_df.sort_values('hit_number', ascending=False, inplace=True)\n",
    "sum_pm_df = sum_pm_df[['FASTA_id','hit_number']]\n",
    "sum_pm_df = sum_pm_df.reset_index(drop=True)\n",
    "raw_pm_df = pd.concat(raw_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of use of `%%capture` to suppress output, need a separate cell to see results summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FASTA_id</th>\n",
       "      <th>hit_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S288CchrIV</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DBVPG6765chrIV</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YPS128chrIV</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y12chrIV</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YPS138chrIV</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UWOPS034614chrIV</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBS432chrIV</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UWOPS919171chrIV</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N44chrIV</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DBVPG6044chrIV</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SK1chrIV</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FASTA_id  hit_number\n",
       "0         S288CchrIV          25\n",
       "1     DBVPG6765chrIV          25\n",
       "2        YPS128chrIV          25\n",
       "3           Y12chrIV          25\n",
       "4        YPS138chrIV          24\n",
       "5   UWOPS034614chrIV          24\n",
       "6        CBS432chrIV          24\n",
       "7   UWOPS919171chrIV          24\n",
       "8           N44chrIV          24\n",
       "9     DBVPG6044chrIV          23\n",
       "10          SK1chrIV          23\n",
       "11    UFRJ50816chrXI          23"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_pm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume that '+ 2' should be added to the hit_number for each based on S288C according to [Corden, 2013](https://www.ncbi.nlm.nih.gov/pubmed/24040939); however, that is something that could be explored further.\n",
    "\n",
    "All the raw data is there for each strain in `raw_pm_df`. For example, the next cell shows how to view the data associated with the summary table for strain UFRJ50816:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FASTA_id</th>\n",
       "      <th>hit_number</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>strand</th>\n",
       "      <th>matching pattern</th>\n",
       "      <th>query pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>1</td>\n",
       "      <td>CTD_heptad-1</td>\n",
       "      <td>1542</td>\n",
       "      <td>1548</td>\n",
       "      <td>1</td>\n",
       "      <td>FSPTSPT</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>2</td>\n",
       "      <td>CTD_heptad-2</td>\n",
       "      <td>1549</td>\n",
       "      <td>1555</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPA</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>3</td>\n",
       "      <td>CTD_heptad-3</td>\n",
       "      <td>1556</td>\n",
       "      <td>1562</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>4</td>\n",
       "      <td>CTD_heptad-4</td>\n",
       "      <td>1563</td>\n",
       "      <td>1569</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>5</td>\n",
       "      <td>CTD_heptad-5</td>\n",
       "      <td>1570</td>\n",
       "      <td>1576</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>6</td>\n",
       "      <td>CTD_heptad-6</td>\n",
       "      <td>1577</td>\n",
       "      <td>1583</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>7</td>\n",
       "      <td>CTD_heptad-7</td>\n",
       "      <td>1584</td>\n",
       "      <td>1590</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>8</td>\n",
       "      <td>CTD_heptad-8</td>\n",
       "      <td>1591</td>\n",
       "      <td>1597</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>9</td>\n",
       "      <td>CTD_heptad-9</td>\n",
       "      <td>1598</td>\n",
       "      <td>1604</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>10</td>\n",
       "      <td>CTD_heptad-10</td>\n",
       "      <td>1605</td>\n",
       "      <td>1611</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>11</td>\n",
       "      <td>CTD_heptad-11</td>\n",
       "      <td>1612</td>\n",
       "      <td>1618</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>12</td>\n",
       "      <td>CTD_heptad-12</td>\n",
       "      <td>1619</td>\n",
       "      <td>1625</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>13</td>\n",
       "      <td>CTD_heptad-13</td>\n",
       "      <td>1626</td>\n",
       "      <td>1632</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>14</td>\n",
       "      <td>CTD_heptad-14</td>\n",
       "      <td>1633</td>\n",
       "      <td>1639</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>15</td>\n",
       "      <td>CTD_heptad-15</td>\n",
       "      <td>1640</td>\n",
       "      <td>1646</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPA</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>16</td>\n",
       "      <td>CTD_heptad-16</td>\n",
       "      <td>1647</td>\n",
       "      <td>1653</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>17</td>\n",
       "      <td>CTD_heptad-17</td>\n",
       "      <td>1654</td>\n",
       "      <td>1660</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>18</td>\n",
       "      <td>CTD_heptad-18</td>\n",
       "      <td>1661</td>\n",
       "      <td>1667</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>19</td>\n",
       "      <td>CTD_heptad-19</td>\n",
       "      <td>1668</td>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>20</td>\n",
       "      <td>CTD_heptad-20</td>\n",
       "      <td>1675</td>\n",
       "      <td>1681</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPN</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>21</td>\n",
       "      <td>CTD_heptad-21</td>\n",
       "      <td>1682</td>\n",
       "      <td>1688</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPS</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>22</td>\n",
       "      <td>CTD_heptad-22</td>\n",
       "      <td>1689</td>\n",
       "      <td>1695</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPTSPG</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UFRJ50816chrXI</td>\n",
       "      <td>23</td>\n",
       "      <td>CTD_heptad-23</td>\n",
       "      <td>1696</td>\n",
       "      <td>1702</td>\n",
       "      <td>1</td>\n",
       "      <td>YSPGSPA</td>\n",
       "      <td>[YF]SP[TG]SP[STAGN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FASTA_id  hit_number         hit_id start   end  strand  \\\n",
       "0   UFRJ50816chrXI           1   CTD_heptad-1  1542  1548       1   \n",
       "1   UFRJ50816chrXI           2   CTD_heptad-2  1549  1555       1   \n",
       "2   UFRJ50816chrXI           3   CTD_heptad-3  1556  1562       1   \n",
       "3   UFRJ50816chrXI           4   CTD_heptad-4  1563  1569       1   \n",
       "4   UFRJ50816chrXI           5   CTD_heptad-5  1570  1576       1   \n",
       "5   UFRJ50816chrXI           6   CTD_heptad-6  1577  1583       1   \n",
       "6   UFRJ50816chrXI           7   CTD_heptad-7  1584  1590       1   \n",
       "7   UFRJ50816chrXI           8   CTD_heptad-8  1591  1597       1   \n",
       "8   UFRJ50816chrXI           9   CTD_heptad-9  1598  1604       1   \n",
       "9   UFRJ50816chrXI          10  CTD_heptad-10  1605  1611       1   \n",
       "10  UFRJ50816chrXI          11  CTD_heptad-11  1612  1618       1   \n",
       "11  UFRJ50816chrXI          12  CTD_heptad-12  1619  1625       1   \n",
       "12  UFRJ50816chrXI          13  CTD_heptad-13  1626  1632       1   \n",
       "13  UFRJ50816chrXI          14  CTD_heptad-14  1633  1639       1   \n",
       "14  UFRJ50816chrXI          15  CTD_heptad-15  1640  1646       1   \n",
       "15  UFRJ50816chrXI          16  CTD_heptad-16  1647  1653       1   \n",
       "16  UFRJ50816chrXI          17  CTD_heptad-17  1654  1660       1   \n",
       "17  UFRJ50816chrXI          18  CTD_heptad-18  1661  1667       1   \n",
       "18  UFRJ50816chrXI          19  CTD_heptad-19  1668  1674       1   \n",
       "19  UFRJ50816chrXI          20  CTD_heptad-20  1675  1681       1   \n",
       "20  UFRJ50816chrXI          21  CTD_heptad-21  1682  1688       1   \n",
       "21  UFRJ50816chrXI          22  CTD_heptad-22  1689  1695       1   \n",
       "22  UFRJ50816chrXI          23  CTD_heptad-23  1696  1702       1   \n",
       "\n",
       "   matching pattern        query pattern  \n",
       "0           FSPTSPT  [YF]SP[TG]SP[STAGN]  \n",
       "1           YSPTSPA  [YF]SP[TG]SP[STAGN]  \n",
       "2           YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "3           YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "4           YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "5           YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "6           YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "7           YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "8           YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "9           YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "10          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "11          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "12          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "13          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "14          YSPTSPA  [YF]SP[TG]SP[STAGN]  \n",
       "15          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "16          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "17          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "18          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "19          YSPTSPN  [YF]SP[TG]SP[STAGN]  \n",
       "20          YSPTSPS  [YF]SP[TG]SP[STAGN]  \n",
       "21          YSPTSPG  [YF]SP[TG]SP[STAGN]  \n",
       "22          YSPGSPA  [YF]SP[TG]SP[STAGN]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UFRJ50816 = raw_pm_df[raw_pm_df['FASTA_id'] == 'UFRJ50816chrXI'].sort_values('hit_number', ascending=True).reset_index(drop=True)\n",
    "UFRJ50816"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary and raw data will be packaged up into one file in the cell below. One of the forms will be a tabular text data ('.tsv') files that can be opened in any spreadsheet software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Text file of summary details saved as 'RPB1_orthologs_patmatch_results_summary.tsv'.\n",
      "Text file of raw details saved as 'RPB1_orthologs_patmatch_results_summary.tsv'.\n",
      "Collected pattern matching results gathered and saved as `RPB1_orthologs_patmatch_results.tar.gz`."
     ]
    }
   ],
   "source": [
    "# save summary and raw results for use elsewhere (or use `.pkl` files for reloading the pickled dataframe into Python/pandas)\n",
    "patmatch_fn_prefix = gene_name + \"_orthologs_patmatch_results\"\n",
    "patmatchsum_fn_prefix = gene_name + \"_orthologs_patmatch_results_summary\"\n",
    "patmatch_fn = patmatch_fn_prefix + \".tsv\"\n",
    "pkl_patmatch_fn = patmatch_fn_prefix + \".pkl\"\n",
    "patmatchsum_fn = patmatchsum_fn_prefix + \".tsv\"\n",
    "pklsum_patmatch_fn = patmatchsum_fn_prefix + \".pkl\"\n",
    "import pandas as pd\n",
    "sum_pm_df.to_pickle(pklsum_patmatch_fn)\n",
    "sum_pm_df.to_csv(patmatchsum_fn, sep='\\t') # keep index is default\n",
    "sys.stderr.write(\"Text file of summary details saved as '{}'.\".format(patmatchsum_fn))\n",
    "raw_pm_df.to_pickle(pkl_patmatch_fn)\n",
    "raw_pm_df.to_csv(patmatch_fn, sep='\\t') # keep index is default\n",
    "sys.stderr.write(\"\\nText file of raw details saved as '{}'.\".format(patmatchsum_fn))\n",
    "# pack up archive dataframes\n",
    "pm_dfs_list = [patmatch_fn,pkl_patmatch_fn,patmatchsum_fn,pklsum_patmatch_fn]\n",
    "archive_file_name = patmatch_fn_prefix+\".tar.gz\"\n",
    "!tar czf {archive_file_name} {\" \".join(pm_dfs_list)} # use the list for archiving command\n",
    "sys.stderr.write(\"\\nCollected pattern matching\"\n",
    "                 \" results gathered and saved as \"\n",
    "                 \"`{}`.\".format(archive_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the tarballed archive of the files to your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
